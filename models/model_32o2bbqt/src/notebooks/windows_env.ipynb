{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YXxEdBDMFwU",
    "outputId": "6309c12d-63f7-4f18-c2d3-a4dcdf549342"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import git\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ENVIRONMENT\"] = \"windows\"\n",
    "os.environ[\"REPO_DIR\"] = git.Repo(search_parent_directories=True).git.rev_parse(\"--show-toplevel\")\n",
    "os.environ[\"ROOT_DIR\"] = os.path.abspath(os.path.join(os.getenv(\"REPO_DIR\"), os.pardir))\n",
    "os.environ[\"MODEL_ID\"] = \"32o2bbqt\"\n",
    "os.environ[\"MODEL_DIR\"] = f\"{os.getenv('REPO_DIR')}/models/model_{os.getenv('MODEL_ID')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Repository Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, f\"{os.getenv('REPO_DIR')}/src\")\n",
    "from helpers import *\n",
    "\n",
    "sys.path.insert(0, f\"{os.getenv('MODEL_DIR')}/src\")\n",
    "from methods import *\n",
    "from architecture import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbx_access_token = getpass(\"Enter your DropBox access token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if datasets need to be downloaded to your local machine\n",
    "download_datasets = False\n",
    "\n",
    "if download_datasets:\n",
    "    download_datasets_from_dropbox(\n",
    "        dbx_access_token = dbx_access_token,\n",
    "        include_all_datasets = True,\n",
    "        use_thread = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh4-Gg6vL2R3"
   },
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0t0BM_lS_6yq"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 10\n",
    "val_batch_size = 10\n",
    "val_ratio = 0.2                         # Percent of training set used for validation\n",
    "lookback = {\"count\": 0, \"stride\": 1}    # Prior frames model has access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dropbox access token uninitialized. Could not download model weights. Using default model weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m set_device()\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbx_access_token\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdbx_access_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m create_datasets(\n\u001b[0;32m     10\u001b[0m     device \u001b[38;5;241m=\u001b[39m device,\n\u001b[0;32m     11\u001b[0m     include_all_datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     lookback \u001b[38;5;241m=\u001b[39m lookback\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m create_dataloaders(\n\u001b[0;32m     18\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m train_dataset,\n\u001b[0;32m     19\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m val_dataset,\n\u001b[0;32m     20\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch_size,\n\u001b[0;32m     21\u001b[0m     val_batch_size \u001b[38;5;241m=\u001b[39m val_batch_size\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users/Awrod/OneDrive/Desktop/UMARV/ScenePerception/UMARV-CV-ScenePerception/models/model_32o2bbqt/src\\methods.py:85\u001b[0m, in \u001b[0;36minitialize_model\u001b[1;34m(device, dbx_access_token, lookback, reset_weights)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dbx_access_token \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropbox access token uninitialized. Could not download model weights. Using default model weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     model \u001b[38;5;241m=\u001b[39m download_model_weights(model, dbx_access_token)\n",
      "\u001b[1;31mValueError\u001b[0m: Dropbox access token uninitialized. Could not download model weights. Using default model weights."
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "model = initialize_model(\n",
    "    device = device,\n",
    "    dbx_access_token = dbx_access_token,\n",
    "    lookback = lookback,\n",
    "    reset_weights = False\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset = create_datasets(\n",
    "    device = device,\n",
    "    include_all_datasets = False,\n",
    "    include_real_world_datasets = True,\n",
    "    val_ratio = val_ratio,\n",
    "    lookback = lookback\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader = create_dataloaders(\n",
    "    train_dataset = train_dataset,\n",
    "    val_dataset = val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    val_batch_size = val_batch_size\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss_hist, val_performance_hist, best_val_performance = training_loop(\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    train_dataloader = train_dataloader,\n",
    "    val_dataloader = val_dataloader,\n",
    "    val_dataset = val_dataset,\n",
    "    dbx_access_token = dbx_access_token,\n",
    "    num_epochs = num_epochs,\n",
    "    critiqueing_metric = \"Accuracy\",\n",
    "    upload_weights_to_dropbox = True,\n",
    "    auto_stop = False,\n",
    "    verbose = True,\n",
    "    display_sample_results = True,\n",
    "    display_sample_results_every_n_epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loss_history(train_loss_hist)\n",
    "\n",
    "graph_performance_history(\n",
    "    performance_hist = val_performance_hist,\n",
    "    split = \"Val\",\n",
    "    metrics = [\"Accuracy\", \"Mean IoU\"]\n",
    ")\n",
    "\n",
    "show_sample_results(\n",
    "    model = model,\n",
    "    dataset = val_dataset,\n",
    "    device = device,\n",
    "    num_samples = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_on_benchmarks(\n",
    "    model = model,\n",
    "    device = device,\n",
    "    all_benchmarks = True,\n",
    "    num_sample_results = 2,\n",
    "    lookback = lookback\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
